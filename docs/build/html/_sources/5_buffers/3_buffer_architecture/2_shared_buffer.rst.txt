Shared Buffer
=============

По числу существующих в мире коробок этот вариант, однозначно, на первом месте. 

    .. figure:: https://fs.linkmeup.ru/images/articles/buffers/shared_buffer.png           
           :width: 500
           :align: center

Используется Shared Buffer на немодульных устройствах без фабрики коммутации, в которых установлен один чип (обычно, но может быть больше).

| Аппаратно - это память (обычно SRAM), встроенная прямо в чип - она так и называется **on-chip** (OCB). Много туда не засунешь, поэтому объём до 100 МБ.
| Зачастую это единственная память, которая в одночиповых устройствах используется для буферизации.
| Пусть, однако, эта кажущаяся простота не вводит вас в заблуждение - для того, чтобы в десятки мегабайтов поместить трафик сотни портов 100Гб/с, да ещё и обеспечить отсутствие потерь, за ними должны скрываться годы разработок и нетривиальная архитектура.
| А так оно и есть - я чуть ниже неглубоко вас окуну.

Итак, есть соблазн эту память взять и просто равномерно разделить между всеми портами. Такой статический дизайн имеет право на жизнь, но сводит на нет возможность динамически абсорбировать всплески трафика.

Гораздо более привлекательным выглядит следующий вариант:

Dedicated + Shared
------------------

| Из доступной памяти каждому порту выделяется определённая небольшая часть - это **Dedicated Buffer**. За каждым портом кусочек памяти законодательно закреплён и не может быть использован другими портами. То есть при любых обстоятельствах у порта будет свой защищённый кусочек. Минимальный размер Dedicated Buffer где-то настраивается, где-то нет. Но лучше без основательного понимания в дефолты не лезть.
| Доля каждого порта в абсолютных цифрах очень маленькая - порядка единиц кБ.
| Гарантируемый минимум выделяется для хранения как входящих пакетов, так и выходящих.

| Остальная часть памяти как раз общая - **Shared Buffer** - может быть использована любым портом по мере необходимости. Из неё динамически выделяются куски для тех интерфейсов, которые испытывают перегрузку. 
| Например, если чип пытается на один из интерфейсов передать больше трафика, чем тот способен отправлять в единицу времени, то эти пакеты сначала заполняют выделенный для этого порта буфер, а когда он заканчивается, автоматически начинают складываться в динамически выделенный буфер из общей памяти. Как только все пакеты обработаны, память освобождается.
| Под общий буфер может быть отдано 100% той памяти, что осталась после вычитания из неё выделенных для портов кусочков (Dedicated). Но она так же может быть перераспределена - за счёт общего буфера можно увеличить выделенные. Так, если выделить 80% под Shared, то оставшиеся 20% равномерно распределятся по Dedicated.

Наличие Shared Buffer'а решает огромную проблему, позволяя сглаживать всплески трафика, когда перегрузку испытывает один или несколько интерфейсов.

| Однако вместе с тем за общую память начинаются соревноваться разные порты одновременно. И серьёзная перегрузка на одном порту может вызвать потери на другом, которому нужно было всего лишь несколько килобайтов общей памяти, чтобы не дропнуть пакет.
| Одним из способов облегчить эту ситуацию является увеличение выделенных буферов за счёт уменьшения общего.
| Но это всегда зона компромиссных решений - сокращая размер общей памяти, мы уменьшаем и объёмы всплесков, которые чип может сгладить.
| Кроме того Lossless трафик требует к себе ещё более щепетильного отношения.

Поэтому зачастую, помимо Dedicated и Shared буферов, резервируют ещё **Headroom buffers**.

Headroom buffers
----------------

| Это последний способ сохранить пакеты, когда даже общий буфер уже забит. Естественно, он тоже отрезается от общей памяти, поэтому на первый взгляд выглядит не очень логичным откусить от общей памяти кусок, назвать его по-другому и сказать, мол, мы всё оптимизировали.
| На самом деле Headroom буферы решают довольно специфическую задачу - помочь lossless приложениям с **PFC** - `Priority-based Flow Control <https://www.juniper.net/documentation/en_US/junos/topics/concept/cos-qfx-series-congestion-notification-understanding.html#jd0e554>`_.

| PFC - это механизм Ethernet Pause, который умеет притормаживать не всю отправку, а только по конкретным приоритетам Ethernet CoS.
| Например, два приложения на отправителе: RoCE и репликация БД. Первое - чувствительная к задержкам и потерям вещь, второе - массивные данные.
| Коммутатор, заметив заполнение общего буфера, отправляет Pause для более низкого приоритета, тем самым притормаживая репликацию, но не RoCE.
| Задача буфера Headroom здесь в том, чтобы сохранить in-flight пакеты приоритетной очереди (те, что сейчас в кабеле), пока Pause летит к отправителю с просьбой притормозить.
То есть пакеты репликации начнут дропаться, когда заполнится общий буфер, а пакеты RoCE будут складываться в Headroom. 

    Помимо lossless headroom бывает и headroom для обычного трафика, чтобы помочь сохранить более приоритетный. Но это на домашнее задание.

    .. figure:: https://fs.linkmeup.ru/images/articles/buffers/buffer_types.png          
           :width: 800
           :align: center

| При наступлении перегрузки буферы будут задействованы в следующем порядке.
| Для входящего best-effort трафика:

    #. Dedicated buffers
    #. Shared buffers

Для входящего lossless трафика:

    #. Dedicated buffers
    #. Shared buffers
    #. Lossless headroom buffers

Для всего исходящего трафика:

    #. Dedicated buffers
    #. Shared buffers

Разумеется, описанное выше лишь частный пример, и от вендора к вендору ситуация может различаться (разительно).

Например бродкомовские чипы (как минимум Trident и Tomahawk) имеют внутреннее разделение памяти по группам портов. Общая память делится на порт-группы по 4-8 портов, которые имеют свой собственный кусочек общего буфера. Порты из одной группы, соответственно буферизируют пакеты только в своём кусочке памяти и не могут занимать другие. Это тоже один из способов снизить влияние перегруженных портов друг на друга. Такой подход иногда называют **Segregated Buffer**.

Admission Control
-----------------

Admission Control - входной контроль - механизм, который следит за тем, можно ли пакет записывать в буфер. Он не является специфичным для Shared-буферов, просто в рамках статьи - это лучшее место, чтобы о нём рассказать.

| Формально Admission Control делится на Ingress и Egress.
| Задача **Ingress Admission Control** - во-первых, вообще убедиться, что в буфере есть место, а, во-вторых, обеспечить справедливое использование памяти.
| Это означает, что у каждого порта и очереди всегда должен быть гарантированный минимальный буфер. А ещё несколько входных портов не оккупируют целиком весь буфер, записывая в него всё новые и новые пакеты.

Задача **Egress Admission Control** - помочь чипу абсорбировать всплески, не допустив того, чтобы один или несколько выходных портов забили целиком весь буфер, получая всё новые и новые пакеты с кучи входных портов.

В случае Shared Buffer оба механизма срабатывают в момент первичного помещения пакета в буфер. То есть никакой двойной буферизации и проверки не происходит. 

| Как именно понять, сколько буфера занято конкретным портом/очередью и главное, сколько ещё можно ему выдать?
| Это может быть статический порог, одинаковый для всех портов, а может быть и динамически меняющийся, регулируемый параметром **Alpha**.

Alpha
-----

Итак, почти во всех современных чипах память распределяется динамически на основе информации о том, сколько общей памяти вообще свободно и сколько ещё можно выделить для данного порта/очереди.

На самом деле минимальной единицей аккаунтинга является не порт/очередь, а регион (в терминологии Мелланокс). Регион - это кортеж: *(входной порт, Priority Group на входном порту, выходной порт, Traffic Class на выходном порту)*.

| Каждому региону назначается динамический порог, сколько памяти он может под себя подмять. При его превышении, очевидно, пакеты начинают дропаться, чтобы не влиять на другие регионы.
| Этот порог вычисляется по формуле, множителями которой являются объём свободной на данный момент памяти и параметр **alpha**, специфичный для региона и настраиваемый:

    .. code-block:: bash
    
       Threshold [Bytes] = alpha * free_buffer [Bytes]

| Его значение варьируется от 1/128 до примерно 8 с шагом х2. Чем больше эта цифра, тем больший объём свободной памяти доступен региону.
| Например, если на коммутаторе 32 региона, то:
| при alpha=1/64 каждому региону будет доступна 1/64 часть свободной памяти, и даже при максимальной утилизации они все смогут использовать только половину буфера.
| при alpha=1/32 вся память равномерно распределится между регионами, ни один из них не сможет влиять на другие, а при полной утилизации 100% памяти будет занято.
| при alpha=1/16 каждый регион может претендовать на больший объём памяти. И если все регионы разом начнут потреблять место, то им всем не хватит, потому что памяти потребовалось бы 200%. То есть это своего рода переподписка, позволяющая сглаживать всплески.
*Предполагаем тут, что значение alpha одинаково для всех регионов, хотя оно может быть настроено отдельно для каждого.*

| При получении каждого пакета, механизм Admission Control вычисляет актуальный порог для региона, которому принадлежит пакет. Если порог меньше размера пакета, тот отбрасывается.
| Если же больше, то он помещается в буфер и уже не будет отброшен никогда, даже если регион исчерпал все лимиты. Объём свободной памяти уменьшается на размер пакета.
| Это происходит для каждого приходящего на чип пакета.


Написанное выше об Admission Control и Alpha может быть справедливо не только для Shared Buffers, но и для других архитектур, например, VoQ.

**Дальнейшее чтиво:**

    * Если в жизни не хватает страданий: `Design and Implementation of a Shared Memory Switch Fabric <https://montazeri.iut.ac.ir/sites/montazeri.iut.ac.ir/files/file_pubwdet/32083_0.pdf>`_
    * `Understanding the Alpha Parameter in the Buffer Configuration of Mellanox Spectrum Switches <https://community.mellanox.com/s/article/understanding-the-alpha-parameter-in-the-buffer-configuration-of-mellanox-spectrum-switches>`_
    * Programming Guide'ы коммерческих микросхем (NDA кровью, помним, да?).


| Crossbar и Shared Buffer - это архитектуры, которые могут использоваться для устройств фиксированной конфигурации (возможно, даже multi-chip), но не подходят для модульных.
| Взглянем же теперь на них.

| Дело в том, что они состоят из нескольких линейных карт, каждая из которых несёт как минимум один самостоятельный чип коммутации.
| И этот чип, будь то ASIC, NP или даже CPU не может в своей внутренней памяти динамически выделять буферы для тысяч очередей выходных интерфейсов - кишка тонка. 

    .. figure:: https://fs.linkmeup.ru/images/articles/buffers/modular_chassis.png           
           :width: 800
           :align: center

Далее поговорим про архитектуры памяти для модульных шасси:

.. toctree::
   :maxdepth: 1

   ../3_buffer_architecture/3_oq.rst
   ../3_buffer_architecture/4_iq.rst
   ../3_buffer_architecture/5_cioq.rst
   ../3_buffer_architecture/6_voq.rst