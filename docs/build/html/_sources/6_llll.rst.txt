6. Low-latency lossless сети
============================

| С развитием RoCE, RDMA, nVME over Fabric к сети стали появляться другие, неслыханные доселе требования: и каждый пакет ценен и времени терять нельзя. Одновременно. И хуже того, мы хотим по максимуму утилизировать имеющиеся линки, чтобы они не простаивали.
| И все требования оправданы - осуждать их мы здесь не будем.

Так что же можно сделать? На самом деле, как я уже говорил выше, условия сети датацентра хороши тем, что информация о перегрузке очень быстро доносится до отправителей. Поэтому и реакция на потерянный пакет не заставит себя долго ждать.

| Но что если нам не отбрасывать пакет, а каким-то другим способом сообщить отправителю, что нужно замедлиться? 
| Здесь есть несколько конкурирующих подходов.

  * `ECN-Based`_
  * `Bandwidth-Delay Product Based`_
  * `RTT-BASED`_


ECN-Based
---------

Транзитное устройство, готовящееся испытать перегрузку, явным образом сообщает отправителям о том, что нужно охладить свою страсть.

Прозорливые инженеры заложили в IP целых 8 бит под QoS, и только 6 мы задействовали под DSCP, а 2 бита были зарезервированы для целей **ECN - Explicit Congestion Notification**.

Надолго забытый механизм сегодня извлекают из ящика стола, сдувают с него пыль, и вставляют в шкатулку, на которой нацарапано или `DCTCP <https://tools.ietf.org/html/rfc8257>`_

| Транзитное устройство при заполнении буфера больше, чем до определённого порога, выставляет в заголовках IP обрабатываемых пакетов бит CE (Congestion Encountered) и отправляет пакет дальше.
| Получатель, увидев в пришедшем пакете этот флаг, сообщает отправителю о перегрузке и о том, что нужно снизить скорость.

Классический TCP может обнаружить только уже существующую перегрузку, а DCTCP, используя ECN, узнаёт о том, что она только приближается, и пробует её избежать. 

Есть и другие реализации TCP, поддерживающие ECN, например, HTCP.

| Нюанс с ECN-based Congestion Control механизмами в том, что до поры до времени они ничего не знают о надвигающейся перегрузке, а потом должен пройти ещё целый RTT, чтобы отправитель узнал, что какое-то транзитное устройство к ней близко. | К тому времени, как отправители начнут снижать скорость, перегрузка уже может или рассосаться или наоборот дойти до уровня, когда начнутся дропы. 


Bandwidth-Delay Product Based
-----------------------------

Другие реализации замеряют эффективную полосу сети совместно с RTT, то есть сколько можно ещё напихать в трубу до того, как это создаст затор и увеличит задержку.

Примерами таких протоколов являются `BBR <https://habr.com/ru/post/322430/>`_ и `H-TCP <https://www.hamilton.ie/net/draft-leith-tcp-htcp-00.txt>`_.

RTT-BASED
---------

| В конце концов есть элегантные механизмы, которые замеряют время прохода трафика туда-обратно.
| Идея провальная для MAN/WAN-сегментов, и, честно говоря, при попытке программной вычисления RTT тоже.
| TIMELY от Google с аппаратным offload'ом вычисления RTT один из наиболее удачных примеров.

На самом деле, если бы не видео с прекрасной девушкой, рассказывающей про технические детали TIMELY, не знаю даже стал ли бы я упоминать про него. Наслаждайтесь, но берегите уши: `TIMELY: RTT-based Congestion Control for the Datacenter <https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F2829988.2787510&file=p537-mittal.webm&download=true>`_.

