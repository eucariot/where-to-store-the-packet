Уровни и плоскости
==================

    .. figure:: https://habrastorage.org/webt/v2/tx/q1/v2txq1ilntxxc5qbcrzu__xwhjo.png
           :align: center

Это настолько важные вещи, что мы не можем не дать им определения.

В работе оборудования можно выделить три уровня/плоскости:

  * **Forwarding/Data Plane**
  * **Control Plane**
  * **Management Plane**

    .. figure:: https://habrastorage.org/webt/zy/sq/ip/zysqipnbjnnjybnt1qxaexuiuec.png           
           :align: center

====

Forwarding/Data Plane
---------------------

| **Плоскость пересылки**.
| Главная задача сети - доставить трафик от одного приложения другому. И сделать это максимально быстро, как в плане пропускной способности, так и задержек.
| Соответственно главная задача узла - максимально быстро передать вошедший пакет на правильный выходной интерфейс, успев поменять ему заголовки и применив политики.
| Поэтому существуют заранее заполненные таблицы передачи пакетов - таблицы коммутации, таблицы маршрутизации, таблицы меток, таблицы соседств итд.
| Реализованы они могут быть на специальных чипах CAM, TCAM, работающих на скорости линии (интерфейса). А могут быть и программными.

  Примеры:

    #. Принять Ethernet-кадр, посчитать контрольную сумму, проверить есть ли `SMAC <http://lookmeup.linkmeup.ru/#term605>`_ в таблице MAC-адресов. Найти `DMAC <http://lookmeup.linkmeup.ru/#term606>`_ в таблице MAC-адресов, определить интерфейс, передать кадр.
    #. Принять MPLS-пакет, определить входной интерфейс и входную метку. Выполнить поиск в таблице меток, определить выходной интерфейс и выходную метку. Свопнуть. Передать.
    #. Пришёл поток пакетов. Выходным интерфейсом оказался `LAG <http://lookmeup.linkmeup.ru/#term443>`_. Решение, в какие из интерфейсов их отправить, тоже принимается на Forwarding Plane.


Разница между Data и Forwarding Plane
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| В абсолютном большинстве случаев считается, что Data и Forwarding Plane - это одно и то же.
| Однако иногда их разделяют.
| Тогда Data Plane означает именно манипуляции с полезной нагрузкой: процесс доставки пакета от входного интерфейса к выходному и обработку его в буферах.
| А Forwarding Plane - это обработка заголовков и принятие решения о пересылке.

Примерно так:

    .. figure:: https://habrastorage.org/webt/if/c1/j3/ifc1j3de74krybbfjolg186uunq.png           
       :width: 800
       :align: center

====

Control Plane
-------------

| **Плоскость управления**.
| Всему голова. Она **заранее** заполняет таблицы, по которым затем будет передаваться трафик.
| Здесь работают протоколы со сложными алгоритмами, которые дорого или невозможно реализовать аппаратно.

| Например, `алгоритм Дейкстры <http://lookmeup.linkmeup.ru/#term256>`_ реализовать на чипе можно, но сложно. Так же сложно сделать выбор лучшего маршрута BGP или определение FEC и рассылку меток. Кроме того, для всего этого пришлось бы делать отдельный чип или часть чипа, которая практически не может быть переиспользована.
| В такой ситуации лучше пожертвовать сабсекундной сходимостью в пользу удобства и цены.

| Поэтому ПО запускается на CPU общего назначения.
| Получается медленно, но гибко - вся логика программируема. И на самом деле скорость на Control Plane не важна. Однажды вычисленный маршрут инсталлируется в FIB, а дальше всё на скорости линии.
| Вопрос скорости Control Plane возникает при обрывах, флуктуациях на сети, но он сравнительно успешно решается механизмами TE HSB, TE FRR, IP FRR, VPN FRR, когда запасные пути готовятся заранее на том же Control Plane.


  Примеры:

    #. Запустили сеть с IGP. Нужно сформировать Hello, согласовать параметры сессий, обменяться базами данных, просчитать кратчайшие маршруты, инсталлировать их в Таблицу Маршрутизации, поддерживать контакт через периодические Keepalive.
    #. Пришёл `BGP Update <http://linkmeup.ru/blog/65.html>`_. Control Plane добавляет новые маршруты в таблицу BGP, выбирает лучший, инсталлирует его в Таблицу Маршрутизации, при необходимости пересылает Update дальше.
    #. Администратор включил `LDP <http://linkmeup.ru/blog/154.html>`_. Для каждого префикса создаётся `FEC <http://lookmeup.linkmeup.ru/#term477>`_, назначается метка, помещается в таблицу меток, анонсы уходят всем LDP-соседям.
    #. Собрали два коммутатора в стек. Выбрать главный, проиндексировать интерфейсы, актуализировать таблицы пересылок - задача Control Plane.

Работа и реализация Control Plane универсальна: ЦПУ + оперативная память: работает одинаково хоть на стоечных маршрутизаторах, хоть на виртуальных сетевых устройствах.

| Эта система - не мысленный эксперимент, не различные функции одной программы, это действительно физически разделённые тракты, которые взаимодействуют друг с другом.
| Началось всё с разнесения плоскостей на разные платы. Далее появились стекируемые устройства, где одно выполняло интеллектуальные операции, а другое было лишь интерфейсным придатком. 
| Вчерашний день - это системы вроде Cisco Nexus 5000 Switch + Nexus 2000 Fabric Extender, где 2000 выступает в роли выносной интерфейсной платы для 5000.
| Где-то в параллельной Вселенной тихо живёт SDN разлива 1.0 - с Openflow-like механизмами, где Control Plane вынесли на внешние контроллеры, а таблицы пересылок заливаются в совершенно глупые коммутаторы.
| Наша реальность и ближайшее будущее - это наложенные сети (Overlay), настраиваемые SDN-контроллерами, где сервисы абстрагированы от физической топологии на более высоком уровне иерархии.


| Разделение на Control и Forwarding Plane позволило отвязать передачу данных от работы протоколов и настройки сети, а это повлекло значительное повышение масштабируемости и отказоустойчивости.
| Так один модуль плоскости управления может поддерживать несколько интерфейсных модулей.
| В случае сбоя на плоскости управления механизмы `GR, NSR <https://www.cisco.com/c/en/us/products/collateral/ios-nx-os-software/high-availability/solution_overview_c22-487228.html>`_, `GRES <https://www.juniper.net/documentation/en_US/junos/topics/concept/gres-overview.html>`_ и `ISSU <https://www.juniper.net/documentation/en_US/junos/topics/concept/issu-on-qfx5100-overview.html>`_ помогают плоскости пересылки продолжать работать будто ничего и не было.

====

Management Plane
----------------

| **Плоскость или демон наблюдения**. 
| Не всегда его выделяют в самостоятельную плоскость, относя его задачи к Control Plane, а иногда, выделяя, называют Monitoring или Config.
| Этот модуль отвечает за конфигурацию и жизнедеятельность узла. Он следит за такими параметрами, как:

  * Конфигурация устройства
  * Температура
  * Утилизация ресурсов
  * Электропитание
  * Скорость вращения вентиляторов
  * Работоспособность плат и модулей.


  Примеры:
    #. Упал интерфейс - генерируется авария, лог и трап на систему мониторинга
    #. Поднялась температура чипа - увеличивает скорость вращения вентиляторов
    #. Обнаружил, что одна плата перестала отвечать на периодические запросы - выполняет рестарт плат - вдруг поднимется.
    #. Оператор подключился по SSH для снятия диагнонстической информации - CLI также обеспечивается Management Plane'ом.
    #. Приехала конфигурация по Netconf - Management Plane проверяет и применяет её. При необходимости инструктирует Control Plane о произошедших изменениях и необходимых действиях.

Итак:
**Forwarding Plane** - передача трафика на основе таблиц пересылок - собственно то, из чего оператор извлекает прибыль. Требуется скорость.
**Control Plane** - служебный уровень, необходимый для формирования условий для работы Forwarding Plane. Требуется интеллект
**Management Plane** - модуль, следящий за общим состоянием устройства и обеспечивающий интерфейс конфигурации.

Вместе они составляют самодостаточный узел в сети пакетной коммутации.

    .. figure:: https://habrastorage.org/webt/zy/sq/ip/zysqipnbjnnjybnt1qxaexuiuec.png           
           :align: center

| Разделение на Control и Forwarding/Data Plane - не абстрактное - их функции действительно выполняют разные чипы на плате.
| Так Control Plane обычно реализован на связке CPU+RAM+карта памяти, а Forwarding Plane на ASIC, FPGA, CAM, TCAM.