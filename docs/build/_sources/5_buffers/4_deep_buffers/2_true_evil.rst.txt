Большие буферы - добро или зло?
===============================

В целом это довольно старая дилемма. Подольше похранить или пораньше дропнуть?

Конечно, всем приложениям хочется lossless low-latency сеть. Даже жирному некрасивому торренту. Но так не бывает и кем-то нужно жертвовать.
И мы долгое время живём с инертной мыслью , что часть приложений могут потерпеть задержки, а вот терять трафик совсем не хочется. Не в малой степени этому способствовало и то, что потери - это измеримая характеристика с более или менее понятными границами - потерь быть не должно. А что задержка? Вроде можно чётко сказать, что единицы миллисекунд - это хорошо, а секунды - это плохо. А между ними - зона спекуляций. Как оценить влияние вариаций задержки для рядового TCP-трафика?
Поэтому и спрос на устройства с большими буферами есть - никто не хочет терять трафик.

А теперь я выскажу не самое популярное мнение - потери - это хорошо. 
Так уж вышло, что один из транспортных протоколов, фиксирует перегрузки, опираясь на потери. 
Дроп в очереди на сетевом устройстве означает, что на нём случился затор - это он не по своему капризу. И будет совсем не лишним, если отправители немного приуменьшат свои congestion window.
Именно так и работают все классические (и не очень) реализации TCP Congestion Control. 
Соответственно на устройствах с глубокими буферами во время заторов пакеты будут долго копиться, не отбрасываясь. Когда они всё-таки дойдут до получателя и тот их ACKнет, отправитель не только не снизит скорость, но может даже её увеличить, если у него сейчас режим Slow Start или Congestion Avoidance. 
Можно взглянуть и дальше: растущая очередь взвинчивает RTT, что соответственно влечёт за собой увеличение RTO таймеров на отправителях, тем самым замедляя обнаружение потерь. 
То есть сеть лишается своего практически единственного инструмента управления перегрузками.
И таким образом архитекторы, пытающиеся решить вопрос заторов на сети путём увеличения буферов, усугубляют ситуацию ещё больше.

Ситуация, описанная выше, называется **bufferbloat** - распухание буфера.
Википедия иронично замечает:

    Проект www.bufferbloat.net иронично определил этот термин, как «ухудшение производительности Интернета, вызванное предыдущими попытками её улучшения»

Отбросы - санитары сети. Ко всеобщему удивлению, уменьшение очереди до одного пакета зачастую может кардинально улучшить ситуацию, особенно в условиях датацентра (только не сочтите это за дельный совет).

    Справедливости ради следует заметить, что современные реализации TCP - BBR2, TIMELY ориентируются не только и не столько на потери, сколько на RTT и `BDP <https://en.wikipedia.org/wiki/Bandwidth-delay_product>`_.
    Гугловый QUIC - надстройку над UDP - следует отнести сюда же. 

Внутри фабрики датацентра RTT ультракороткий - зачастую меньше 1 мс. Это позволяет среагировать на потерю очень быстро и купировать перегрузку в её зачатке.
Собственно поэтому практически все ASIC'и для датацентровых коммутаторов имеют только крохотную on-chip память.
Хотя и появилась в последние годы тенденция к глубоких буферам и тут.
И этому даже находится `объяснение <https://forums.juniper.net/t5/Enterprise-Cloud-and/Not-all-deep-buffer-switches-are-created-equal/ba-p/318393>`_.

| Особая история на границе датацентра (или на устройствах доступа в сети провайдера или на магистральных сетях).
| **Во-первых**, это места, которые обычно заведомо строятся с переподпиской, поскольку WAN-линки дорогие, что автоматически означает, что ситуации, в которых трафика приходит больше, чем способен переварить интерфейс, ожидаемы. А значит нужна возможность пакеты хранить и обрабатывать их в соответствии с приоритетами. Большие буферы позволяют сгладить всплески.
| **Во-вторых**, обычно приложения настолько чувствительные к задержкам, никто не будет пытаться растягивать на этот сегмент. Например, RoCE или распределённое хранилище. Для чуть менее чувствительных, таких как телефония, в больших буферах выделяется приоритетная очередь. 
| **В-третьих**, тут задержки на устройстве всё ещё делают основной вклад в общее время доставки, но уже не настолько драматический.

Итак, устройства с большим объёмом памяти годятся в места где заложена переподписка или могут появиться заторы.

Что стоит отметить, так это то, что в датацентрах тоже есть ситуации, в которых 16-64 МБ буферов может не хватить, даже несмотря на отсутствие переподписки.
Два типичных примера - это обработка Big Data и Storage. 

**Анализ Big Data**. Кластера Map-Reduce - это сотни и тысячи машин, которые перемалывают параллельно огромные массивы данных по заданию Master-узла, заканчивают примерно одинаково и все разом начинают возвращать ответы на Master-узел. Ситуация называется `Incast <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.1375&rep=rep1&type=pdf>`_. Длится она порядка нескольких десятков миллисекунд и потом исчезает. 
On-chip память неспособна вместить эти данные - значит будет много дропов, значит ретрансмиты, значит общее снижение производительности.

**Storage**. Это штука крайне чувствительная к потерям и тоже гоняющая массивные объёмы данных. В случае хранилки тоже лучше не терять ничего. Но обычно она при этом и к задержкам предъявляет строгие требования, поэтому такие приложения обсудим пониже.

Однако при этом крайне редко они единственные потребители сети в датацентрах, другим приложениям нужна низкая задержка.

Впрочем, это легко решается выделением очередей QoS с ограничением максимальной доступной глубины. И весь вопрос заключается тогда только в том, готова ли компания заплатить за глубокие буферы, возможно, не использовать их  и поддерживать конфигурацию QoS. 

Но в любой ситуации лучше следовать правилу: `use shallow ASIC buffers when you can and use deep buffers when you must <https://www.nextplatform.com/2019/07/23/the-switch-router-war-is-over-and-hyperscalers-won/>`_.

**Критика глубоких буферов**: 

    * `Arista’s Big Buffer B.S. <https://packetpushers.net/aristas-big-buffer-b-s/>`_
    * `Incast <https://people.ucsc.edu/~warner/Bufs/incast.html>`_
    * `Speeding Applications in Data Center Networks. The Interaction of Buffer Size and TCP Protocol Handling and its Impact on Data-Mining and Large Enterprise IT Traffic Flows <http://miercom.com/pdf/reports/20160210.pdf>`_
    
Кстати, показательная таблица типичных задержек:

    .. figure:: https://fs.linkmeup.ru/images/articles/buffers/latencies.png           
           :width: 630
           :align: center

*`Источник <https://people.ucsc.edu/~warner/Bufs/Buffering-WP_August_2017.pdf>`_*.